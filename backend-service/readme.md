# ğŸ§ª Backend Challenge â€“ Worldsys

## ğŸ“˜ Contexto

Este microservicio desarrollado en **Node.js** se encarga de procesar diariamente un archivo de gran tamaÃ±o (1â€¯GB aprox) con registros de clientes. Corre dentro de un contenedor Docker y estÃ¡ preparado para ejecutarse en un entorno Kubernetes con Linux como sistema operativo.

El objetivo principal es **leer, validar y almacenar eficientemente** los datos vÃ¡lidos del archivo en una base de datos **SQL Server**, exponiendo al mismo tiempo un endpoint `/health` para monitorear el estado del servicio incluso durante el procesamiento.

---

## ğŸ¯ Objetivo cumplido

âœ… Procesar correctamente el contenido del archivo `CLIENTES_IN_0425.dat`  
âœ… Insertar los datos procesados en una tabla SQL Server  
âœ… Exponer el endpoint `/health` mientras se procesa  
âœ… Preparado para escalar a archivos 5 veces mÃ¡s grandes  
âœ… ValidaciÃ³n y descarte de lÃ­neas corruptas  
âœ… Logs informativos y seguimiento de progreso  

---

## ğŸ“¦ Estructura del proyecto

```
backend-service/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts               # Punto de entrada del servicio
â”‚   â”œâ”€â”€ processor.ts           # LÃ³gica de procesamiento lÃ­nea por lÃ­nea
â”‚   â”œâ”€â”€ db.ts                  # ConexiÃ³n a la DB y bulk insert
â”‚   â”œâ”€â”€ health.ts              # Endpoint /health
â”‚   â””â”€â”€ types.ts               # Interface Cliente
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql               # Script de creaciÃ³n de base de datos y tabla
â”‚
â”œâ”€â”€ .env                       # Variables de entorno
â”œâ”€â”€ Dockerfile                 # Imagen del microservicio
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n de servicios
â””â”€â”€ README.md                  # Este archivo
```

---

## âš™ï¸ Requisitos

- Docker y Docker Compose instalados
- Node.js (solo si se desea ejecutar el generador manualmente)

---

## ğŸš€ Instrucciones para levantar el entorno local

1. ClonÃ¡ este repositorio

```bash
git clone https://github.com/tu-usuario/worldsys-backend-challenge.git
cd worldsys-backend-challenge/backend-service
```

2. ConfigurÃ¡ tu archivo `.env` (ya provisto de ejemplo)

```env
DB_USER=sa
DB_PASSWORD=Qnf]00JX)Lv~6N3
DB_NAME=clientes_db
DB_SERVER=sqlserver
DB_PORT=1433
FILE_PATH=/app/input/CLIENTES_IN_0425.dat

PORT=3000

```

3. LevantÃ¡ los servicios con Docker Compose:

```bash
docker-compose up --build
```

Esto harÃ¡ lo siguiente:

- IniciarÃ¡ SQL Server en un contenedor
- EjecutarÃ¡ el script `init.sql` para crear la base de datos y tabla `Clientes`
- IniciarÃ¡ el servicio Node.js y comenzarÃ¡ el procesamiento automÃ¡tico del archivo `CLIENTES_IN_0425.dat`

---

## ğŸ§ª GeneraciÃ³n del archivo de prueba

Dentro del repositorio se incluye un generador opcional de datos:

```bash
cd ../backend-challenge-file-ingestion/data-generator
npm install
npx ts-node src/generateFile.ts
```

Esto generarÃ¡ el archivo `CLIENTES_IN_0425.dat` en:

```
data-generator/challenge/input/
```

Este archivo serÃ¡ automÃ¡ticamente montado en el contenedor como `/app/input/CLIENTES_IN_0425.dat`.

### ParÃ¡metros del generador (modificables en `src/generateFile.ts`):

```ts
const RECORDS = 100_000;   // Cantidad de lÃ­neas a generar
const ERROR_RATE = 0.2;    // 20% de lÃ­neas con errores intencionales
```

---

## ğŸ—ƒï¸ Formato esperado del archivo

Cada lÃ­nea debe tener el siguiente formato, separado por `|`:

```txt
<nombre>|<apellido>|<dni>|<estado>|<fechaIngreso>|<esPep>|<esSujetoObligado>
```

### Ejemplo vÃ¡lido

```
MarÃ­a|GÃ³mez|45678901|Activo|11/13/2021|true|false
```

### Ejemplo invÃ¡lido (descartado con warning)

```
Carlos|PÃ©rez|32165498|Inactivo|99/99/9999||
```

---

## ğŸ§© DefiniciÃ³n de tabla en SQL Server

El script `sql/init.sql` crea la tabla `Clientes` con los siguientes campos:

```sql
NombreCompleto NVARCHAR(100) NOT NULL,
DNI BIGINT NOT NULL,
Estado VARCHAR(10) NOT NULL,
FechaIngreso DATE NOT NULL,
EsPEP BIT NOT NULL,
EsSujetoObligado BIT NULL,
FechaCreacion DATETIME NOT NULL
```

---

## ğŸ” Logs y control de errores

- El sistema descarta automÃ¡ticamente lÃ­neas malformadas o con campos invÃ¡lidos.
- Se muestra el conteo final de lÃ­neas vÃ¡lidas e invÃ¡lidas.
- Cada batch se inserta usando `bulk insert` para mÃ¡xima eficiencia.
- Todos los errores se registran en consola para fÃ¡cil debugging.

---

## ğŸ› ï¸ Endpoint disponible

```http
GET /health
```

### Ejemplo de respuesta:

```json
{
  "status": "ok",
  "timestamp": "2025-07-10T23:00:00.000Z"
}
```

---

## ğŸ“ˆ Consideraciones de escalabilidad

- Lectura con `readline` (streaming) para evitar uso excesivo de RAM
- Procesamiento en batches configurables (`batchSize`)
- Preparado para escalar horizontalmente si se divide el archivo por partes
- Tolerancia a errores y logs precisos
- Cumple con el lÃ­mite de recursos (`128Mi / 100m`) al evitar buffers grandes o carga total en memoria

---
